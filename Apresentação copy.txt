import cv2
import pytesseract
import os
import numpy as np
from gtts import gTTS
from pygame import mixer
import mtranslate
import keras.models
import speech_recognition as sr
import threading
import time

# Configuração do Tesseract
pytesseract.pytesseract.tesseract_cmd = r'C:\Program Files\Tesseract-OCR\tesseract.exe'
os.environ['TESSDATA_PREFIX'] = r'C:\Program Files\Tesseract-OCR\tessdata'
tessdata_dir_config = '--tessdata-dir "C:\\Program Files\\Tesseract-OCR\\tessdata"'

# Dicionário de idiomas suportados pelo gTTS
idiomas = {
    'Afrikaans': 'af', 'Árabe': 'ar', 'Bengali': 'bn', 'Cantonês': 'yue', 'Catalão': 'ca',
    'Chinês': 'zh-tw', 'Croata': 'hr', 'Checo': 'cs',
    'Dinamarquês': 'da', 'Holandês': 'nl', 'Inglês': 'en', 'Filipino': 'fil', 'Finlandês': 'fi',
    'Francês': 'fr', 'Alemão': 'de', 'Grego': 'el', 'Gujarati': 'gu', 'Hebraico': 'he', 'Hindi': 'hi',
    'Húngaro': 'hu', 'Indonésio': 'id', 'Italiano': 'it', 'Japonês': 'ja', 'Javanês': 'jw', 'Coreano': 'ko',
    'Letão': 'lv', 'Lituano': 'lt', 'Malaio': 'ms', 'Marata': 'mr', 'Norueguês': 'no', 'Polonês': 'pl',
    'Português (Brasil)': 'pt-br', 'Português Portugal': 'pt-pt', 'Romeno': 'ro', 'Russo': 'ru',
    'Sérvio': 'sr', 'Eslovaco': 'sk', 'Esloveno': 'sl', 'Espanhol': 'es', 'Suaíli': 'sw',
    'Sueco': 'sv', 'Tâmil': 'ta', 'Telugu': 'te', 'Tailandês': 'th', 'Turco': 'tr', 'Ucraniano': 'uk',
    'Vietnamita': 'vi', 'Galês': 'cy'
}

# Inicializar o mixer
mixer.init()

# Lock para controle de execução
fala_lock = threading.Lock()

# Função para sintetizar e reproduzir fala
def falar(texto):
    with fala_lock:
        tts = gTTS(text=texto, lang='pt-br')
        audio_file = 'fala.mp3'
        tts.save(audio_file)
        
        mixer.music.load(audio_file)
        mixer.music.play()
        while mixer.music.get_busy():
            time.sleep(0.1)  # Esperar para garantir que o áudio tenha terminado de tocar
        
        mixer.music.unload()  # Descarregar o arquivo de áudio
        try:
            os.remove(audio_file)
        except PermissionError:
            time.sleep(0.5)
            os.remove(audio_file)

# Função para reconhecer comandos de voz
def reconhecer_comando():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        recognizer.adjust_for_ambient_noise(source)
        falar("Diga algo...")
        try:
            audio = recognizer.listen(source, timeout=2)
            comando = recognizer.recognize_google(audio, language='pt-BR')
            falar("Você disse: " + comando)
            return comando.lower()
        except sr.WaitTimeoutError:
            falar("Tempo de escuta excedido")
            return None
        except sr.UnknownValueError:
            falar("Não entendi o que você disse")
            return None
        except sr.RequestError as e:
            falar("Erro ao solicitar resultados")
            return None

# Função para selecionar o idioma via comando de voz
def selecionar_idioma_por_voz():
    falar("Diga o nome do idioma que você deseja no próximo comando:")
    comando = reconhecer_comando()
    if comando:
        for nome, codigo in idiomas.items():
            if nome.lower() in comando:
                return codigo
    falar("Idioma não reconhecido, usando Português do Brasil")
    return 'pt-br'  # Idioma padrão

# Carregar o modelo treinado
def load_trained_model(model_path):
    model = keras.models.load_model(model_path)
    return model

# Função de pré-processamento de imagem 
def preprocess_image(image):
    resized_image = cv2.resize(image, (128, 128))
    processed_image = resized_image / 255.0
    return processed_image

# Função para converter a saída do modelo em texto 
def convert_prediction_to_text(image):
    text = pytesseract.image_to_string(image, lang='por', config=tessdata_dir_config)
    return text

# Função para permitir que o usuário escolha um frame na tela da câmera via comando de voz
def select_frame_por_voz(cap, result):
    frame_selected = None
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Falha ao capturar a imagem da câmera")
            continue
        cv2.imshow('frame', frame)

        if result['comando']:
            comando = result['comando']
            result['comando'] = None
            if comando and ("capturar" in comando or "enter" in comando):
                frame_selected = frame
                break
            elif comando and ("sair" in comando or "f" in comando):
                result['fim'] = True
                break
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break
    return frame_selected

# Função para obter comandos de voz em uma thread separada
def obter_comandos_de_voz(result):
    while not result['fim']:
        comando = reconhecer_comando()
        if comando:
            result['comando'] = comando

# Selecionar idioma via comando de voz
idioma_selecionado = selecionar_idioma_por_voz()

# Carregar o modelo treinado
model_path = 'C:/Users/willi/Documents/FACULDADE/10º SEMESTRE/PROJETO FINAL 2/CODIGO TCC1/OFICIAL - APRESENTAÇÃO/H5/H5.h5'
model = load_trained_model(model_path)

# Inicializar a câmera
cap = cv2.VideoCapture(1)  # Usar a câmera padrão para inicializar mais rápido

if not cap.isOpened():
    print("Erro ao abrir a câmera")
    exit()

# Dicionário para armazenar o resultado da thread de reconhecimento de voz
result = {'comando': None, 'fim': False}

# Iniciar a thread para obter comandos de voz
thread = threading.Thread(target=obter_comandos_de_voz, args=(result,))
thread.start()

while True:
    selected_frame = select_frame_por_voz(cap, result)
    if result['fim']:
        break
    if selected_frame is not None:
        gray = cv2.cvtColor(selected_frame, cv2.COLOR_BGR2GRAY)
        processed_image = preprocess_image(gray)
        input_image = np.expand_dims(processed_image, axis=0)
        prediction = model.predict(input_image)

        if prediction is not None:
            text = convert_prediction_to_text(gray)
            print("Texto:", text)

            translated_text = mtranslate.translate(text, 'pt', 'en')
            print("Tradução:", translated_text)

            if translated_text:
                # Bloqueio para leitura do texto capturado
                with fala_lock:
                    tts = gTTS(text=translated_text, lang=idioma_selecionado)
                    audio_file = 'audio.mp3'
                    tts.save(audio_file)

                    mixer.music.load(audio_file)
                    mixer.music.play()
                    while mixer.music.get_busy():
                        time.sleep(0.5)  # Esperar para garantir que o áudio tenha terminado de tocar

                    mixer.music.unload()  # Descarregar o arquivo de áudio
                    os.remove(audio_file)

            cv2.imshow('frame', selected_frame)

cap.release()
cv2.destroyAllWindows()
result['fim'] = True
thread.join()